#' Create object that contains Stan model configuration for `SigRescueR()`
#'
#' This function creates an object that preloads the selected Stan model with Stan model
#' configurations. By preloading the Stan model, it does not need to be loaded internally
#' each time Bayesian inference is used.
#'
#' @param model A character string specifying the Stan model to use. Default = COM-Poisson.
#' @param wamrup An integer to specify the number of warm-up iterations before sampling
#' begins. Default = 2000.
#' @param iter An integer to specify the total number of iterations. The number of posterior
#' sampling is equal to the total number of iterations - the number of warm-up iterations.
#' Default = 6000. Thus, 4000 posterior sampling.
#' @param chains An integer specifying the number of Markov chains to run. Default = 4.
#'
#' @import rstan
#' @export


SigRescueRModel <- function(model = "COM-Poisson", warmup = 2000, iter = 6000, chains = 4) {
  if(model == "COM-Poisson") {
    ## Model name
    model <- "COM-Poisson"
    ## Preload model
    stan_file <- system.file("stan", "com_poisson.stan", package = "SigRescueR")
    smodel <- stan_model(file=stan_file)

    ## Get path to model
    spath <- stan_file

    ## Store configuration as list
    model_setup <- list(model = model, smodel = smodel, spath = spath,
                        warmup = warmup, iter = iter, chains = chains,
                        cores = chains)

    ## Assign to global environment
    assign("model", model_setup, envir = .GlobalEnv)
  }
}

#' Execute Bayesian inference
#'
#' This function creates temporary `.rds` files and R script used to run Bayesian inference
#' using `model_runner.R`. It prepares model data and launch a R process.
#'
#' @param objects A list of objects from the global environment that are temporary saved  and
#' used for Bayesian inference. The list must include `model`, `treatment`, `control`, `output_path`,
#' and `filename`. `model` is an object that contains Stan model configuration, such as number
#' of warm-ups, iterations, and chains, generated by `SigRescueRModel()`. `treatment` is a data
#' frame representing the mutational catalogue for exposed samples. Each column corresponds to a
#' sample and must include a `MutationType` column (first column) specifying the mutation context
#' (e.g. `A[C>A]A`), and all other values must be integers. `control` is a data frame representing
#' the mutational catalogue for control samples. Similar to treatment, and must include a
#' `MutationType` column (first column) matching the order of the treatment, and all values must be
#' normalized (e.g. relative frequencies). `output_path` is a character string specifying the full
#' path where the output `.rda` file will be saved. `filename` is a character string specifying the
#' file name.
#' @param script_path A character string specifying the R script to run the model. Default = model_runner.R
#'
#' @export

SigRescueR <- function(objects,
                       script_path = system.file("scripts", "model_runner.R", package = "SigRescueR")) {

  tmp_data_files <- list()

  # Save each object to a temporary RDS
  if (!is.null(objects)) {
    for (obj in objects) {
      if (!exists(obj, envir = parent.frame())) stop("Object not found: ", obj)
      tmp_file <- tempfile(fileext = ".rds")
      saveRDS(get(obj, envir = parent.frame()), tmp_file)
      tmp_data_files[[obj]] <- tmp_file
    }
  }

  # Build wrapper script
  wrapper_code <- c()

  # Load objects at start of script
  for (obj in names(tmp_data_files)) {
    wrapper_code <- c(wrapper_code, paste0(obj, " <- readRDS('", tmp_data_files[[obj]], "')"))
  }

  # Source the main script
  wrapper_code <- c(wrapper_code, paste0("source('",script_path,"')"))

  # Write temporary R script
  tmp_script <- tempfile(fileext = ".R")
  writeLines(wrapper_code, tmp_script)

  # Run script
  system2("Rscript", tmp_script, wait = TRUE)
}

#' Extracts posterior sampling from `SigRescueR()`.
#'
#' This function extract the posterior samples from the Bayesian model and computes the
#' posterior mean for the exposure and background while providing some reconstruction
#' metrics and generates the exposure mutational catalogue.
#'
#' @param res An object returned by `SigRescueR()` containing posterior estimates.
#' @param MutationType A character vector specifying the ordered mutation context.
#'
#' @import rstan
#' @import lsa
#' @import tidyverse
#' @export


SigRescueRExtract <- function(res, MutationType) {
  ## Function to compute Poisson deviance
  poisson_deviance <- function(y, y_hat) {
    # handle zeros safely
    terms <- ifelse(y == 0, -y_hat, y * log(y / y_hat) - (y - y_hat))
    return(2 * sum(terms))
  }

  ## Function to compute Jensen Shannon Divergence
  js_divergence <- function(p, q, base = 2) {
    # Normalize counts to probability distributions
    p <- p / sum(p)
    q <- q / sum(q)

    m <- 0.5 * (p + q)

    kl_pm <- sum(ifelse(p == 0, 0, p * log(p / m, base)))
    kl_qm <- sum(ifelse(q == 0, 0, q * log(q / m, base)))

    js <- 0.5 * (kl_pm + kl_qm)
    return(js)
  }

  ## List to store summary results
  samp.res <- list()
  ## List to store cleaned signatures
  samp.cleaned <- list()

  ## Process each sample within file
  for(samp in names(res)) {
    message("Processing ", samp)
    ## Get posterior sampling
    fit <- res[[samp]]
    posterior <- rstan::extract(fit$fit)

    ## Extract background and exposure activity
    all_theta <- as.data.frame(posterior$norm_theta_b) %>% ## background activity
      mutate(norm_theta_t = posterior$norm_theta_t) %>% ## treatment activity
      sweep(x = ., MARGIN = 1, STATS = rowSums(.), FUN = "/") %>% ## Row normalize
      colMeans() ## Compute posterior mean

    ## Extract normalized posterior mean for exposure and background activity
    theta_t <- all_theta[length(all_theta)]
    theta_b <- all_theta[-length(all_theta)]

    ## Extract posterior exposure profile and select lower bound (2.5% credible interval)
    s_t <- apply(posterior$s_t, 2, quantile, probs = 0.025)
    s_t <- s_t / sum(s_t) ## normalize

    ## Convert relative probability distribution to count
    ## (Profile * activity) * total mutation count
    reconstruct_s_t <- (s_t * theta_t) * sum(fit$s_t)

    ## Do same for background profile
    reconstruct_s_b <- sapply(1:length(theta_b), function(x) {
      (as.numeric(fit$s_b[,x]) * theta_b[x]) * sum(fit$s_t)
    })

    ## If more than 1 background supplied, rowSum to get total mutation by mutation context
    if(length(reconstruct_s_b)>1) {
      reconstruct_s_b <- rowSums(reconstruct_s_b)
    }

    ## Sum count for exposure and background to get reconstructed
    reconstructed <- reconstruct_s_t + reconstruct_s_b

    ## If more than 1 background supplied, sum background activity
    if(length(theta_b) > 1) {
      theta_b <- sum(theta_b)
    }

    ## Reconstruction Evaluation ##
    p.dev_recon <- poisson_deviance(fit$s_t, reconstructed)/length(fit$s_t) ## Poisson Deviance
    js_recon <- js_divergence(fit$s_t/sum(fit$s_t), reconstructed/sum(reconstructed)) ## Jensen Shannon Divergence
    cs_recon <- lsa::cosine(fit$s_t, reconstructed)[[1]] ## Cosine Similarity

    ## Store summary in samp.res
    samp.res[[samp]] <- data.frame(sample = samp,
                                   original = sum(fit$s_t),
                                   reconstructed = sum(reconstructed),
                                   poisson_dev = p.dev_recon,
                                   js_recon = js_recon,
                                   cs_recon = cs_recon,
                                   theta_t = theta_t,
                                   theta_b = theta_b)

    ## Store cleaned profiles in samp.cleaned
    samp.cleaned[[samp]] <- data.frame(cleaned = reconstruct_s_t) %>% 'colnames<-' (samp)
  }
  ## Convert list to data frame
  samp.res <- as.data.frame(do.call(rbind, samp.res)) %>% remove_rownames()
  samp.cleaned <- as.data.frame(do.call(cbind, samp.cleaned)) %>%
    'rownames<-' (MutationType) %>%
    rownames_to_column(var = "MutationType")

  ## Assign them to global environment
  assign("samp.cleaned", samp.cleaned, envir = .GlobalEnv)
  assign("samp.res", samp.res, envir = .GlobalEnv)
}
